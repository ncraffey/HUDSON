{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime Enemy Detector in Call of Duty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the base overlay from Pynq and set up our HDMI I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# based off of https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_face_detect_hdmi.ipynb\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xafbe0c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize IO\n",
    "hdmi_in.configure(PIXEL_RGB)\n",
    "hdmi_out.configure(hdmi_in.mode, PIXEL_RGB)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can import the libraries for image processing, and define a function for drawing shapes on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_rectangle(draw_point):\n",
    "    cv2.rectangle(clip, draw_point, (draw_point[0] + 80, draw_point[1] + 80), (0, 0, 255), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can set up OpenCV's \"Simple Blob Detector\" and configure the parameters it will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "params.minThreshold = 50\n",
    "params.maxThreshold = 80\n",
    "\n",
    "params.filterByArea = True\n",
    "params.minArea = 120\n",
    "#params.maxArea = 300\n",
    "\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    "\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our function for processing the frame, making it easier for the blob detector to find blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    # ret, clip = cv2.threshold(blur, 90, 255, cv2.THRESH_BINARY)\n",
    "    # clip = cv2.Canny(gray, 60, 120, L2gradient=True) \n",
    "    return blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the main runloop to show the processed image on HDMI out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 20.958168506622314\n",
      "Frames per second:  22.902764611723143\n",
      "time reading frames: 4.033932685852051\n",
      "time blurring : 1.7011969089508057\n",
      "time keypoints: 10.468169927597046\n",
      "Time drawing points: 0.3900907039642334\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "numframes = 480\n",
    "start = time.time()\n",
    "timestamp = time.time()\n",
    "timeReadingFrames = 0\n",
    "timeBlurring = 0\n",
    "timeKeypoints = 0\n",
    "timeDrawingPoints = 0\n",
    "for ff in range(numframes):\n",
    "    timestamp = time.time()\n",
    "    clip = hdmi_in.readframe()\n",
    "    timeReadingFrames += (time.time() - timestamp)\n",
    "    \n",
    "    # Only do the processing every 5th frame, else just pass the frame through\n",
    "    # this increases framerate from ~6 FPS to ~25\n",
    "    # TODO: get the box to stay for an extra two frames after\n",
    "    # TODO: Hardware accelerate\n",
    "    # TODO: make the bubbles actually form around enemies\n",
    "    if (ff % 5 == 0):\n",
    "        timestamp = time.time()\n",
    "        blurred = process_image(clip)\n",
    "        timeBlurring += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        keypoints = detector.detect(blurred)\n",
    "        timeKeypoints += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        clip_with_keypoints = cv2.drawKeypoints(blurred, keypoints, clip, (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        timeDrawingPoints += (time.time() - timestamp)\n",
    "\n",
    "            #cv2.imshow(\"Keypoints\", clip)\n",
    "\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[:] = clip\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    else:\n",
    "        hdmi_out.writeframe(clip)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"total time: \" + str(end-start))\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))\n",
    "print(\"time reading frames: \" + str(timeReadingFrames))\n",
    "print(\"time blurring : \" + str(timeBlurring))\n",
    "print(\"time keypoints: \" + str(timeKeypoints))\n",
    "print(\"Time drawing points: \" + str(timeDrawingPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 26.869354963302612\n",
      "Frames per second:  35.72843491446446\n",
      "time to B&W: 1.0969409942626953\n",
      "time Gaussian blur : 1.768928050994873\n",
      "time canny: 8.875206470489502\n",
      "Time back to clr: 0.6325278282165527\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_filters_hdmi.ipynb\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "numframes = 960\n",
    "grayscale = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "blurred = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "result = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                           hdmi_in.mode.width), dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "timestamp = time.time()\n",
    "timeBW = 0\n",
    "timeGauss = 0\n",
    "timeCanny = 0\n",
    "timeColor = 0\n",
    "\n",
    "for ff in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    \n",
    "    \n",
    "    if (ff % 5 == 0):\n",
    "        timestamp = time.time()\n",
    "        cv2.cvtColor(inframe,cv2.COLOR_RGB2GRAY,dst=grayscale)\n",
    "        timeBW += (time.time() - timestamp)\n",
    "\n",
    "        inframe.freebuffer()\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.GaussianBlur(grayscale,(5,5),0,dst=blurred)\n",
    "        timeGauss += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.Canny(grayscale, 100, 110, edges=result)\n",
    "        timeCanny += (time.time() - timestamp)\n",
    "    \n",
    "        outframe = hdmi_out.newframe()\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.cvtColor(result, cv2.COLOR_GRAY2RGB,dst=outframe)\n",
    "        timeColor += (time.time() - timestamp)\n",
    "\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    else :\n",
    "        hdmi_out.writeframe(inframe)\n",
    "end = time.time()\n",
    "print(\"total time: \" + str(end-start))\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))\n",
    "print(\"time to B&W: \" + str(timeBW))\n",
    "print(\"time Gaussian blur : \" + str(timeGauss))\n",
    "print(\"time canny: \" + str(timeCanny))\n",
    "print(\"Time back to clr: \" + str(timeColor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
