{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime Enemy Detector in Call of Duty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the base overlay from Pynq and set up our HDMI I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# based off of https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_face_detect_hdmi.ipynb\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.lib.video import *\n",
    "mode = VideoMode(2560, 1600, 24, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xb0158df0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize IO\n",
    "hdmi_in.configure(PIXEL_RGB)\n",
    "hdmi_out.configure(hdmi_in.mode, PIXEL_RGB)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can import the libraries for image processing, and define a function for drawing shapes on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_rectangle(draw_point):\n",
    "    cv2.rectangle(clip, draw_point, (draw_point[0] + 80, draw_point[1] + 80), (0, 0, 255), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can set up OpenCV's \"Simple Blob Detector\" and configure the parameters it will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "params.minThreshold = 10\n",
    "params.maxThreshold = 80\n",
    "\n",
    "params.filterByArea = True\n",
    "params.minArea = 200\n",
    "params.maxArea = 300\n",
    "\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "params.filterByConvexity = False\n",
    "params.minConvexity = 0.87\n",
    "\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our function for processing the frame, making it easier for the blob detector to find blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    # ret, clip = cv2.threshold(blur, 90, 255, cv2.THRESH_BINARY)\n",
    "    # clip = cv2.Canny(gray, 60, 120, L2gradient=True) \n",
    "    return blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the main runloop to show the processed image on HDMI out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second:  3.720274773025581\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# numframes = 60\n",
    "# start = time.time()\n",
    "\n",
    "# for _ in range(numframes):\n",
    "#     clip = hdmi_in.readframe()\n",
    "#     blurred = process_image(clip)\n",
    "#     keypoints = detector.detect(blurred)\n",
    "#     clip_with_keypoints = cv2.drawKeypoints(blurred, keypoints, clip, (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "# #     cv2.imshow(\"Keypoints\", clip)\n",
    "#     outframe = hdmi_out.newframe()\n",
    "#     outframe[:] = clip\n",
    "#     hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second:  11.822246993712536\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_filters_hdmi.ipynb\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "numframes = 200\n",
    "grayscale = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "blurred = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "result = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                           hdmi_in.mode.width), dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    cv2.cvtColor(inframe,cv2.COLOR_RGB2GRAY,dst=grayscale)\n",
    "    inframe.freebuffer()\n",
    "    cv2.GaussianBlur(grayscale,(5,5),0,dst=blurred)\n",
    "    cv2.Canny(grayscale, 100, 110, edges=result)\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.cvtColor(result, cv2.COLOR_GRAY2RGB,dst=outframe)\n",
    "    hdmi_out.writeframe(outframe)\n",
    "end = time.time()\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
