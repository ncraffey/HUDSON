{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime Enemy Detector in Call of Duty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to import the base overlay from Pynq and set up our HDMI I/O."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based off of https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_face_detect_hdmi.ipynb\n",
    "\n",
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "hdmi_in = base.video.hdmi_in\n",
    "hdmi_out = base.video.hdmi_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0xadad3fb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize IO\n",
    "hdmi_in.configure(PIXEL_RGB)\n",
    "hdmi_out.configure(hdmi_in.mode, PIXEL_RGB)\n",
    "\n",
    "hdmi_in.start()\n",
    "hdmi_out.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_in.tie(hdmi_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can import the libraries for image processing, and define a function for drawing shapes on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_rectangle(draw_point):\n",
    "    cv2.rectangle(clip, draw_point, (draw_point[0] + 80, draw_point[1] + 80), (0, 0, 255), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can set up OpenCV's \"Simple Blob Detector\" and configure the parameters it will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "params.minThreshold = 50\n",
    "params.maxThreshold = 80\n",
    "\n",
    "params.filterByArea = True\n",
    "params.minArea = 120\n",
    "#params.maxArea = 300\n",
    "\n",
    "params.filterByCircularity = False\n",
    "params.minCircularity = 0.1\n",
    "\n",
    "params.filterByConvexity = True\n",
    "params.minConvexity = 0.87\n",
    "\n",
    "params.filterByInertia = False\n",
    "params.minInertiaRatio = 0.01\n",
    "\n",
    "detector = cv2.SimpleBlobDetector_create(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define our function for processing the frame, making it easier for the blob detector to find blobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(frame):\n",
    "    orig = frame\n",
    "#     cv2.rectangle(frame, (50,50), (150,150), (255), thickness = 3)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.blur(gray, ksize=(25,25))\n",
    "    ret,th = cv2.threshold(blur,30,255,cv2.THRESH_BINARY)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d137ebb5d6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdmi_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreebuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moutframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdmi_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gray = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "blur = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "result = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                           hdmi_in.mode.width), dtype=np.uint8)\n",
    "\n",
    "while True:\n",
    "    clip = hdmi_in.readframe()\n",
    "    cv2.cvtColor(clip, cv2.COLOR_BGR2GRAY, dst=gray)\n",
    "    cv2.blur(gray, ksize=(25,25), dst=blur)\n",
    "    clip.freebuffer()\n",
    "    outframe = hdmi_out.newframe()\n",
    "    cv2.threshold(blur,30,255,cv2.THRESH_BINARY, dst=outframe)\n",
    "    hdmi_out.writeframe(outframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run the main runloop to show the processed image on HDMI out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 21.755008935928345\n",
      "Frames per second:  22.06388429504532\n",
      "time reading frames: 4.31354022026062\n",
      "time blurring : 1.7280464172363281\n",
      "time keypoints: 10.98567819595337\n",
      "Time drawing points: 0.3894500732421875\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "numframes = 480\n",
    "start = time.time()\n",
    "timestamp = time.time()\n",
    "timeReadingFrames = 0\n",
    "timeBlurring = 0\n",
    "timeKeypoints = 0\n",
    "timeDrawingPoints = 0\n",
    "for ff in range(numframes):\n",
    "    timestamp = time.time()\n",
    "    clip = hdmi_in.readframe()\n",
    "    timeReadingFrames += (time.time() - timestamp)\n",
    "    \n",
    "    # Only do the processing every 5th frame, else just pass the frame through\n",
    "    # this increases framerate from ~6 FPS to ~25\n",
    "    # TODO: get the box to stay for an extra two frames after\n",
    "    # TODO: Hardware accelerate\n",
    "    # TODO: make the bubbles actually form around enemies\n",
    "    if (ff % 5 == 0):\n",
    "        timestamp = time.time()\n",
    "        blurred = process_image(clip)\n",
    "        timeBlurring += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        keypoints = detector.detect(blurred)\n",
    "        timeKeypoints += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        clip_with_keypoints = cv2.drawKeypoints(blurred, keypoints, clip, (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        timeDrawingPoints += (time.time() - timestamp)\n",
    "\n",
    "            #cv2.imshow(\"Keypoints\", clip)\n",
    "\n",
    "        outframe = hdmi_out.newframe()\n",
    "        outframe[:] = clip\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    else:\n",
    "        hdmi_out.writeframe(clip)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"total time: \" + str(end-start))\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))\n",
    "print(\"time reading frames: \" + str(timeReadingFrames))\n",
    "print(\"time blurring : \" + str(timeBlurring))\n",
    "print(\"time keypoints: \" + str(timeKeypoints))\n",
    "print(\"Time drawing points: \" + str(timeDrawingPoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time: 27.43881583213806\n",
      "Frames per second:  34.9869325947947\n",
      "time to B&W: 1.093994140625\n",
      "time Gaussian blur : 1.7678158283233643\n",
      "time canny: 9.295008659362793\n",
      "Time back to clr: 0.6358826160430908\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/Xilinx/PYNQ/blob/master/boards/Pynq-Z1/base/notebooks/video/opencv_filters_hdmi.ipynb\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "numframes = 960\n",
    "grayscale = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "blurred = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                              hdmi_in.mode.width), dtype=np.uint8)\n",
    "result = np.ndarray(shape=(hdmi_in.mode.height, \n",
    "                           hdmi_in.mode.width), dtype=np.uint8)\n",
    "\n",
    "start = time.time()\n",
    "timestamp = time.time()\n",
    "timeBW = 0\n",
    "timeGauss = 0\n",
    "timeCanny = 0\n",
    "timeColor = 0\n",
    "\n",
    "for ff in range(numframes):\n",
    "    inframe = hdmi_in.readframe()\n",
    "    \n",
    "    \n",
    "    if (ff % 5 == 0):\n",
    "        timestamp = time.time()\n",
    "        cv2.cvtColor(inframe,cv2.COLOR_RGB2GRAY,dst=grayscale)\n",
    "        timeBW += (time.time() - timestamp)\n",
    "\n",
    "        inframe.freebuffer()\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.GaussianBlur(grayscale,(5,5),0,dst=blurred)\n",
    "        timeGauss += (time.time() - timestamp)\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.Canny(grayscale, 100, 110, edges=result)\n",
    "        timeCanny += (time.time() - timestamp)\n",
    "    \n",
    "        outframe = hdmi_out.newframe()\n",
    "\n",
    "        timestamp = time.time()\n",
    "        cv2.cvtColor(result, cv2.COLOR_GRAY2RGB,dst=outframe)\n",
    "        timeColor += (time.time() - timestamp)\n",
    "\n",
    "        hdmi_out.writeframe(outframe)\n",
    "    else :\n",
    "        hdmi_out.writeframe(inframe)\n",
    "end = time.time()\n",
    "print(\"total time: \" + str(end-start))\n",
    "print(\"Frames per second:  \" + str(numframes / (end - start)))\n",
    "print(\"time to B&W: \" + str(timeBW))\n",
    "print(\"time Gaussian blur : \" + str(timeGauss))\n",
    "print(\"time canny: \" + str(timeCanny))\n",
    "print(\"Time back to clr: \" + str(timeColor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdmi_out.close()\n",
    "hdmi_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
